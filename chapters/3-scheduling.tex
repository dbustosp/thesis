\chapter{Estrategias de planificación de queries}
\label{cap:epq}


\section{Predicción del tiempo de respuesta a \textit{queries} en un motor de búsqueda}
\label{scheduling:ptrq}
Conocer de antemano la eficiencia de una \textit{query} es una ventaja importante para usar técnicas efectivas de \textit{scheduling} de \textit{queries} en motores de búsqueda. Existen estudios en los cuales la eficiencia es inferida usando \textit{clarity score} \citep{Cronen-Townsend:2002}, que es una forma para evaluar la pérdida de ambigüedad de una query con respecto a la colección. En \citep{He:2004} se propone un conjunto de predictores para la eficiencia de cada \textit{query}. Técnicas de aprendizaje de máquina también han sido estudiadas para predecir la eficiencia de \textit{queries} \citep{Si:2002}. Todos los estudios mencionados anteriormente se han centrado en la efectividad para ser predicciones. La eficiencia también ha sido utilizada para predecir el tiempo de respuesta de una query, identificando las razones por las que ésta puede ser resuelta ineficientemente y evaluando estos factores para predecir el comportamiento de futuras queries \citep{Tonellotto:2011}.

En el predictor propuesto en \citep{Macdonald:2012} está basado en estadísticos  disponibles de los términos de la query. 

\begin{tabular}{|l|}
\hline 
Estadístico del término s(t) \\ 
\hline 
1. Media aritmética del score \\ 
\hline 
2. Media geométrica del score \\ 
\hline 
3. Media armonica del score \\ 
\hline 
4. Puntaje máximo \\ 
\hline 
5. Varianza de puntaje \\ 
\hline 
6.  \\ 
\hline 
Agregadores \\ 
\hline 
Máximo \\ 
\hline 
Varianza \\ 
\hline 
Suma \\ 
\hline 
\end{tabular} 


Este predictor está evaluado comparado con 10.000 queries == individual and combinated


\section{Wand \textit{multi-threaded}}
\label{scheduling:wm}
En esta investigación se asume un sistema que usa el método WAND \citep{Broder:2003} para responder eficientemente los mejores K documentos a una transacción de lectura. Este algoritmo usa un \textit{ranking} basado en una evaluación de dos niveles. En el primer nivel, este usa una cota superior (\textit{upper bound}) al puntaje de cada documento para intentar descartarlos eficientemente. En el segundo nivel se computa el puntaje real de los documentos que pasa el primer nivel. Para hacer que este proceso trabaje eficientemente, se usa una estructura de datos llamada \textit{heap} que va guardando el conjunto de los mejores K documentos hasta determinado instante. El menor puntaje de este conjunto es usado como umbral para las evaluaciones del primer nivel, de esta forma se descarta rápidamente documentos que no pueden ser parte del conjunto final de los \textit{top-K} documentos. Esto permite un eficiente y a la vez seguro proceso de descarte que asegura que en el resultado final se encontrará el conjunto correcto y no se perderán documentos relevantes.

Existen dos formas de implementar WAND \textit{multithreaded}. Uno de ellos es usando \textit{heaps} locales (LH), es decir, un \textit{heap} por \textit{thread} y el otro es usando \textit{heaps} compartidos (SH). (Ahondar...)

\subsection{Wand con heaps locales}
\label{scheduling:whl}
En el esquema LH, cada thread procesa una porción del índice invertido mientras mantiene un heap local con los mejores K documento que el específico thread ha encontrado hasta ahora. Al final del proceso, el resultado de cada thread debe ser reunido en un solo conjunto final global.


\subsection{Wand con heap compartido}
\label{scheduling:whc}
En el esquema SH cada thread procesa una perción del índice. Sin embargo, un solo heap es creado y accedido por todos los threads. En este caso no se requiere de mezcla y el proceso de descarte tiende a ser más eficiente porque los documentos con mayor puntaje tienden a estar en el heap. Sin embargo acceder al heap debe ser controlado por un lock o algún método similar. Ha sido demostrado que SH es generalmente más eficiente para un WAND multihebreado [15] y, después de algunos test ejecutados para comparar el tiempo promedio y la eficiencia de ambos enfoques, nosotros optamos por un enfoque de Wand Heap Compartido para ser usado en los experimentos.





\section{Estrategia \textit{baseline}}
\label{scheduling:baseline}
Una simple manera de construir un sistema que responda a múltiple queries simultáneamente usando múltiple threads es, usando los threads de manera independiente. Para hacer esto, se debe mantener un conjunto de threads consumidores, cada uno de ellos se encargará de responder a queries secuencialmente y todos ellos trabajan en paralelo leyendo las queries desde la misma cola. Esto es lo que en este trabajo se denomina Un Thread Por Query (1TQ), ver Figura X (Profundizar más en esta figura)

Este esquema simple tiene ventajas y desventajas, además que es fácil de implementar y controlar. 

Existen sistemas que tienen que ejecutar un conjunto de queries de un cierto tamaño y luego parar para actualizar la información del índice invertido. Solo después de la fase de actualización, éste es capaz de ejecutar el siguiente conjunto de queries (batch de queries). Al final de cada batch, es posible que algunos threads finalicen su trabajo y que no tengan más queries para procesar, por lo que ellos tienen que esperar que los threads restantes finalicen su trabajo antes que el sistema entre en la fase de actualización. 

Sin embargo, aunque cada thread está secuencialmente ejecutando una query diferente, algunas de estas operaciones puede tomar un tiempo cosiderable, de esta forma se produce una importante pérdide de eficiencia, aunque la intuición nos dice que esto se puede amortizar con trabajos pequeños. Ver Figura 2 (Explicar)




\section{Estrategias de \textit{scheuling}}
\label{scheduling:es}

\subsection{FR}
\label{scheduling:fr}

\subsection{Times}
\label{scheduling:times}

\subsection{TimesRanges}
\label{scheduling:timesranges}




\section{Estrategia de unidades de trabajo}
\label{scheduling:unidadestrabajo}

