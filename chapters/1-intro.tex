\chapter{Introducci\'on}
\label{cap:intro}


\section{Antecedentes y motivaci\'on}
\label{intro:motivacion}
La World Wide Web es conocida como una gran teleraña mundial en la que existen millones de computadores conectados y la que desde el año 1993 crece exponencialmente, a tal punto que es incapaz de detectar sus propios cambios. A medida que pasa el tiempo y la \textit{Web} sigue creciendo, los motores de búsqueda se convierten en una herramienta cada vez más usada e importante para los usuarios. Estas máquinas ayudan a los usuarios a buscar contenido dentro de la \textit{Web}, puesto que conocen en cuáles documentos de la \textit{Web} aparecen qué palabras. Si estas máquinas no existieran, los usuarios estarían obligados a conocer los localizadores de recursos uniformes (\textit{URL}) de cada uno de los sitios a visitar. Además, los motores de búsquedas en cierto modo conectan la \textit{Web}, ya que existe un gran número de páginas Web que no tienen referencia desde otras páginas, siendo el único modo de acceder a ellas a través de un motor de búsqueda \citep{Baeza-Yates:2008}.  

La tendencia actual es incluir lo que han llamado búsqueda en tiempo real, que consiste en incluir en los resultados de las búsquedas documentos actualizados en el pasado muy reciente, por ejemplo, en una ventana de tiempo de minutos. Esto permite incluir en los resultados de las búsquedas a sistemas muy activos respecto de publicación de nuevos documentos, tales como \textit{Twitter}\footnote{http://www.twitter.com}. Esto presenta desafíos importantes para los motores de búsqueda puesto que no solo deben procesar eficientemente a decenas de miles de consultas por segundo, sino que también deben permitir que sus índices invertidos \citep{Zobel:2006} sean actualizados de manera concurrente con las consultas que llegan al sistema. Por lo tanto, es relevante diseñar estrategias que permitan administrar a decenas de miles de usuarios concurrentes por segundo y a la vez ser eficientes.

Típicamente, un motor de búsqueda de gran escala como \textit{Google}\footnote{http://www.google.com} o \textit{Yahoo!}\footnote{http://www.yahoo.com}, recibe del orden de las decenas de miles de consultas por segundo, a lo cual hay que sumarle la cantidad de actualizaciones a los datos del índice que ocurren por segundo. Esto genera cargas de trabajo que deben ser servidas por muchos procesadores organizados de manera de satisfacer dos métricas de eficiencias relevantes:

\begin{enumerate}
  \item El tiempo de respuesta por operación. Este debe ser del orden de las pocas decenas de milisegundos en cada servicio con el fin de poder responder al usuario en tiempos del orden de la fracción de segundo.
  \item El número de transacciones de lectura y/o escrituras servidas por segundo (\textit{throughput}), el cual no debe verse afectado con la intensidad de tráfico de operaciones que llegan al motor de búsqueda.
\end{enumerate}

Los motores de búsquedas verticales hacen distinciones de tópicos específicos, estos son sometidos a la misma intensidad de trabajo que un motor de búsqueda horizontal como \textit{Yahoo!}, la diferencia más importante entre ambos es que estos últimos poseen un índice invertido muy grande, es decir, que cada lista invertida tiene un tamaño lo suficientemente grande como para sustentar de manera eficiente el paralelismo. Por el contrario, esto no ocurre en el caso de motores de búsqueda verticales, donde la cantidad de documentos a ser indexados es menor que los que existen en la \textit{Web} mundial.

1Por otra parte, los procesadores actuales tienden a aumentar cada vez más la cantidad de núcleos, lo cual permite incrementar la cantidad de hilos de ejecución disponibles para procesar consultas. Un enfoque tradicional para realizar el procesamiento de consultas es asignar una hebra para resolver una consulta individual, aquí el paralelismo se logra procesando muchas consultas individuales en diferentes núcleos, una por cada hebra y se maximiza el número de \textit{queries} resolviéndose al mismo tiempo; sin embargo, esto hace que eventualmente una consulta se demore mucho tiempo en ser resuelta. Un enfoque alternativo es utilizar todos los \textit{threads} disponibles en una máquina para resolver cada transación de lectura que llega al sistema, de esta forma se minimizaría el tiempo de resolución por consulta, sin embargo la resolución de \textit{consultas} es secuencial. Quizás sea mejor un punto intermedio en que se pueda resolver consultas a un tiempo considerable y a la vez paralelizar el procesamiento de \textit{queries}.

Hoy en día los motores de búsquedas junto con sus centros de datos consumen el 2\% de la energía mundial, lo cual se espera que en los próximos años esta cifra aumente alrededor del 30\%, puesto que la \textit{Web} se duplica cada ocho meses y el número de nuevos usuarios que se conectan a esta crece año a año, para lo cual se hace casi inevitable el aumento de máquinas (\textit{hardware}) a los centros de procesamiento de datos de compañías dueñas de motores de búsqueda a gran escala. Es por esto que se hace imprescindible diseñar e implementar algoritmos que trabajen en paralelo para de esta forma mejorar el \textit{throughput} de los motores de búsqueda, así se podrá resolver transacciones de manera más rápida en períodos de altas cargas de trabajo y apagar aquellos servidores que fueron prendidos en períodos críticos de carga de trabajo. Llegar a soluciones que aporten a mejorar el tiempo de respuesta de una transacción de lectura y el throughput de un motor de búsqueda, requiere conocimientos de diferentes áreas de ciencias de la computación como: Recuperación de la información, computación paralela, compresión de datos, \textit{scheduling}, entre otras. 

Los desafíos expuestos anteriormente hace que existe una comunidad activa intentando encontrar soluciones eficientes para sistemas de recuperación de la información como los motores de búsqueda.  


\section{Descripci\'on del problema}
\label{intro:problema}
Para proveer un tiempo de respuesta adecuado a cada una de las consultas de los usuarios, los motores de búsquedas operan bajo un nivel de acuerdo de servicio \citep{Jeon:2014}, por ejemplo, garantizar una cota superior de tiempo para la respuesta a una consulta. Para un motor de búsqueda es muy importante reducir el tiempo de ejecución de aquellas consultas que tomarán mucho tiempo en ser resueltas, esto es muchas veces más importante que reducir el tiempo medio de respuesta \citep{Dean:2013}. Por lo anteriormente descrito, se plantea la siguiente pregunta que guiará el presente trabajo: ''¿Es posible diseñar un modelo de procesamiento y de planificación de transacciones de lectura que (1) asegure una cota superior de tiempo de respuesta para las consultas de los usuarios, y (2) minimice el tiempo en procesar lotes de \textit{queries}?''.  

Los motores de búsqueda utilizan un método multihilo llamado \textit{Wand} para obtener el conjunto de los mejores documentos (conjunto \textit{top-K}) para una transacción de lectura, el cual posee dos enfoques: (1) Con \textit{heap} locales, en el que cada hebra procesa una parte del índice invertido y obtiene su propio conjunto \textit{top-K}, posteriormente la hebra maestra hace la combinación de resultatos para obtener el conjunto final. (2) Con \textit{heap} compartido, en el que cada hebra procesa una parte del índice invertido y cada vez que ella encuentra un documento que debe estar dentro del conjunto \textit{top-K} final, se pide acceso exclusivo al \textit{heap} compartido y se inserta. Existen trabajos en donde se estudia ambos enfoques \citep{Rojas:2013}, sin embargo, aún no es posible ser categórico en decir cuál enfoque es mejor que otro. Por lo tanto, para poder crear un modelo eficiente de procesamiento y de planificación de transacciones de lectura primero se debe analizar ambos enfoques y decidir cuál se ajusta de mejor forma al presente contexto.

Decidir si utilizar una o todas las hebras de una máquina para resolver una transacción de lectura dependerá de los objetivos del sistema de recuperación de la información, generalmente estos dos enfoques son limitados. Encontrar un punto medio en donde se pueda cumplir con (1) una cota superior aceptable de tiempo para responder a cada consulta y (2) tener un buen \textit{throughput}, es un desafío importante para un motor de búsqueda. Por lo tanto, a través del presente trabajo se intenta encontrar una forma de asignación eficiente de \textit{threads} a consultas de manera tal que se cumplan los dos requerimientos mencionados anteriormente. 


\section{Solución propuesta}
\label{intro:solucionpropuesta}
La solución propuesta en este trabajo implica el diseño e implementación de estrategias de planificación de transacciones de lectura para motores de búsqueda verticales. A su vez, la estrategia generada como solución tendrá como foco principal una sola máquina, en donde el procesamiento de consultras deberá explicar el multithreading 


\subsection{Caracter\'isticas de la solución}
\label{intro:caracteristicassolucion}
La solución propuesta incluye al menos la implementación de un método de predicción de tiempo de respuesta a transacciones de lectura para la asignación eficiente de hilos de ejecucion, con el objetivo de reducir el tiempo de procesamiento de las consultas. 

Se espera la implementación dos modelos para el procesamiento \textit{multithreading }de consultas: Con \textit{heap} compartido y con \textit{heaps} locales. De esta manera el método Wand toma es flexible para trabajar con una o más hebras. 

La solución que se espera encontrar debería tener estrategias de reordenamiento dinámico de las transacciones que llegan al procesador. 

Finalmente, se espera reunir en un solo esquema las mejores soluciones anteriormente descritas, y mediante experimentación evaluar el rendimiento y efectividad de esta nueva estrategia. Se pretende buscar el esquema óptimo de solución con las implementaciones descritas.

La métrica a optimizar es el número consultas resueltas por unidad de tiempo pero garantizando un tiempo de respuesta individual menor a una cota superior establecida y el tiempo medio en resolver conjuntos de transacciones. Por lo tanto, si se diseña una estrategia de procesamiento de consultas que le permita a cada máquina alcanzar una mayor tasa de resolución de consultas, la recompensa puede ser una reducción del total de nodos desplegados en producción.


\subsection{Prop\'osito de la solución}
\label{intro:propositosolucion}

El primer propósito de la solución es asegurar una cota superior de tiempo en las respuestas de las consultas que llegan al motor de búsqueda, esto implica entregarla al usuario tiempos aceptables en sus búsquedas.

Un segundo propósito de la solución es reducir el tiempo de procesamiento de lotes de queries. Esto traería como beneficio alcanzar un uso más eficiente de los recursos asignados a las operaciones de un motor de búsqueda en un centro de datos, ya que los procesadores serán utilizados de manera más eficiente, esto implicaría que un motor de búsqueda vertical estará preparado de mejor forma para resolver flujos grandes de transacciones y los tiempos en resolver cada transacción será menor.

Finalmente, se espera proveer un modelo de procesamiento y planificación de transacciones de lectura para un motor de búsqueda que sea flexible a la actualización concurrente de su índice invertido. De esta forma se permitirá incluir en las respuestas de las consultas a contenido creado en el pasado muy reciente.

\subsection{Alcances de la solución}
\label{intro:alcancesdelasolucion}

\section{Objetivos del proyecto}
\label{intro:objetivosysolucion}
% Wand de heap compartido y Wand de heaps locales

% Predicción de tiempos de respuestas a queries

% Desarrollar estrategia de planificación por bloques y por unidades de trabajo. 

% Dónde meto el 1T/Q? 
\subsection{Objetivo general}
\label{intro:objetivogeneral}
Diseñar, analizar, implementar y evaluar estrategias de procesamiento y planificación de transacciones de lectura para motores de búsqueda verticales para la \textit{Web}. Estas deben ser capaces de resolver de manera eficiente el problema de procesar decenas de miles de transacciones de lectura, asegurando una cota superior de tiempo de respuesta de cada operación y además ser flexible a la llegada de transacciones de escritura. 


\subsection{Objetivos específicos}
\label{intro:objetivosespecificos}


