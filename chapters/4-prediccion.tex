\chapter{Métodos de predicción de rendimiento}
\label{cap:prediccion}
Lograr bajos tiempos de respuestas para transacciones de lectura es uno de los objetivos principales en el diseño de un motor de búsqueda, ya que de esta forma se le puede entregar una respuesta oportuna al usuario. Aquellas transacciones de lectura que requieren una gran cantidad de tiempo en ser resueltas degradan considerablemente la satisfacción del usuario, y es por esto que las máquinas de búsqueda están optimizadas para reducir el percentil más alto de los tiempos (también llamado \textit{tail latency}) \citep{Jeon:2014}. Paralelizar el procesamiento de cada consulta es una solución promitente para reducir el tiempo de ejecución de estas \citep{Jeon:2013, Tatikonda:2011}, lo cual es posible gracias a los modernos procesadores que existen hoy en día que poseen múltiples núcleos, en donde se puede resolver una consulta paralelizando múltiples hilos de ejecución.

Conocer de antemano la eficiencia de una transacción de lectura es una ventaja muy importante, puesto que aquellas consultas que toman una mayor cantidad de tiempo en ser resueltas se les asigna un mayor número de hilos de ejecución para resolverla, de esta manera se reduce el tiempo de procesamiento de las consultas y se cumple con la cota superior de tiempo establecida. Que un sistema como un motor de búsqueda conozca anticipadamente cuánto tardará una consulta en ser procesada, permite implementar técnicas efectivas de planificación de transacciones de lecturas, por ejemplo, en el contexto de procesamiento paralelo de consultas por lotes (\textit{batches}), se pueden crear grupos de consultas que posean similares tiempos de respuesta, así se tiende a disminuir tanto el desbalance de carga entre los procesadores como el tiempo en procesar el lote completo.

Existen trabajos en donde se estudia la correlación de algunos estadísticos presentes en las listas del índice invertido con el tiempo de respuesta de una transacción de lectura \citep{Macdonald:2012, Hauff:2010, He:2004}. El más intuitivo es el número de documentos que hay en una lista invertida, si una consulta posee términos en que sus listas invertidas son largas (muchos documentos), mayor es el tiempo que toma en ser resuelta. A continuación se presentan los métodos de predicción implementados.  

\section{Método de predicción multilineal}
\label{scheduling:glasgow}
Este método predice el tiempo de respuesta de una transacción de lectura y está basado en una regresión lineal múltiple con 42 variables independientes \citep{Macdonald:2012}. Como la respuesta a una consulta debe ser rápida, los estadísticos obtenidos desde las listas invertidas son previamente calculados en la fase de indexamiento, y en ningún caso es parte del proceso de resolución de la consulta. Los puntajes de los documentos son obtenidos mediante el método de \textit{ranking} BM25. 

Si bien es cierto que la regresión lineal posee 42 variables independientes, desde las listas invertidas se extraerán solo 14 estadísticos, ya que las 42 variables independientes se forman aplicando funciones de agregación sobre estos estadísticos. El estudio y el análisis estadístico de cada una de las variables involucradas en la regresión y su impacto en el tiempo está disponible en \citep{Macdonald:2012, Hauff:2010, He:2004}. A continuación se describe cada uno de los estadísticos $s(t)$ calculados en el proceso de indexamiento \citep{Croft:2009} de un sistema de recuperación de información.


\begin{list}{}{}
	\item \textbf{Media aritmética}. La media aritmética del puntaje de los documentos.

	\item \textbf{Media geométrica}. La media geométrica del puntaje de los documentos.

	\item \textbf{Media harmónica}.  La media harmónica del puntaje de los documentos. 

	\item \textbf{Máximo puntaje}. Se obtiene el puntaje máximo perteneciente a algún documento dentro de la lista invertida. En otras palabras, se obtiene el \textit{upper bound} $UB_t$ de la lista. 

	\item \textbf{Varianza del puntaje}. Se extrae desde a lista invertida del término $t$, la varianza del puntaje de los documentos. 
	
	\item \textbf{Número de documentos}. Largo de la lista invertida. 

	\item \textbf{Número de maximos}. Número de veces en que aparece un nuevo puntaje máximo, es decir, el número de veces en que el \textit{upper bound} es actualizado. 

	\item \textbf{Número de documentos mayor a la media}. Número de documentos con puntaje superior al puntaje promedio. 
	
	\item \textbf{Número de documentos con puntaje máximo}. Número de documentos que poseen el puntaje máximo en la lista invertida del término $t$. 
	
	\item \textbf{Número de documentos dentro del 5\% más alto}. Número de documentos cuyos puntajes están dentro del 5\% superior. 
	
	\item \textbf{Número de documentos dentro del 5\% del umbral (\textit{threshold})}. Número de documentos cuyos puntaje están dentro del 5\% superior o 5\% inferior al \textit{threshold}. Recordar que el \textit{threshold} es el puntaje más bajo dentro del conjunto de \textit{top-K}.
	
	\item \textbf{Número de inserciones en el conjunto de los mejores $K$ documentos}. Para obtener este estadístico se asume que el término $t$ es una consulta con un solo término, se resuelve esta consulta con el método Wand y se calcula el número de inserciones de documentos que se hizo al \textit{heap}. Recordar que las inserciones al \textit{heap} ocurren cuando el puntaje completo del documento, supera al \textit{threshold}.
	
	\item \textbf{Frecuencia inversa de documento del término}. Se calcula el \textit{idf} del término $t$ \citep{Baeza-Yates:2011}.
	
	\item \textbf{Tiempo en ser procesado el término}. Tiempo que toma en ser procesado el término como si fuese una consulta de un solo término.

\end{list}

Los 14 estadísticos descritos anteriormente son la base para la implementación del predictor y estos son calculados por cada término del índice invertido. Adicionalmente se definen tres funciones de agregación que se usará por cada consulta: máximo, varianza y suma. El proceso es el siguiente, para cada consulta que llega al sistema, se toman los 14 estadísticos de cada uno de los términos que la conforman, luego se aplica las funciones de agregación a los estadísticos de los términos. Por ejemplo, suponga que llega dos consultas al sistema $q_1$ y $q_2$, ambas tendrán asociada un vector de 14 estadísticos $E_{q_1}$ y $E_{q_2}$ respectivamente, las funciones de agregación para el estadísticos de la media aritmética será calculado como sigue: $e_1 = max\{E_{q_1}(0), E_{q_2}(0)\}$, $e_2 = var\{E_{q_1}(0), E_{q_2}(0)\}$, $e_3 = sum\{E_{q_1}(0), E_{q_2}(0)\}$. De esta forma, con solo el primer estadístico (la media aritmética) se obtienen tres variables independientes. Si esto se extrapola a cada estadístico, se obtienen los 42 requeridos por el método. 
La Tabla \ref{tabla:estadisticosGlasgow} muestra un resumen de lo escrito anteriormente en donde se muestra cada uno de los estadísticos y los agregadores a utilizar. 

\begin{table}[!ht]
\centering
\caption{Resumen de los estadísticos para la predicción multilineal}
\begin{tabular}{|l|}
\hline
\multicolumn{1}{|c|}{Estadísticos de términos $s(t)$} \\ \hline
1. Media aritmética \\ 
2. Media geométrica \\ 
3. Media harmónica \\ 
4. Puntaje máximo \\ 
5. Varianza del puntaje \\ 
6. Número de documentos \\ 
7. Número de máximos \\ 
8. Número docs $>$ media \\ 
9. Número docs = máximo puntaje \\ 
10. Número docs dentro del 5\% más alto \\
11. Número docs dentro del 5\% del \textit{threshold} \\ 
12. Número de inserciones al conjunto top-K \\ 
13. IDF \\ 
14. Tiempo en resolver $t$ como consulta \\ \hline
\multicolumn{1}{|c|}{Agregadores A()} \\ \hline
a. Máximo \\ 
b. Varianza  \\ 
c. Suma \\ \hline
\end{tabular}
\label{tabla:estadisticosGlasgow}
\end{table}

\section{Método de predicción neuronal}
\label{scheduling:neuronal}
Se implementa un método de predicción basado en una red neuronal \textit{backpropagation} \citep{Rumelhart:1988}. La característica de este tipo de redes es que utilizando al menos una capa oculta puede aproximar cualquier tipo de función o relación continua entre un grupo de variables de entrada y salida, debido a que utiliza un método de entrenamiento en la que se propaga el error hacia atrás, de esta forma la red neuronal va generalizando una asociación entre la entrada y salida \citep{Fausett:1994}. 

Para la implementación del modelo se utilizan las mismas 42 variables independientes del esquema anterior con dos neuronas en la capa oculta, la idea es que el tiempo que toma la predicción no genere un impacto negativo en el tiempo de procesamiento de la consulta. El objetivo es minimizar el error de la estimación de tiempo.