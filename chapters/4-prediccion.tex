\chapter{Métodos de predicción de rendimiento}
\label{cap:prediccion}
Lograr bajos tiempos de respuesta para transacciones de lectura es uno de los principales objetivos en el diseño de un motor de búsqueda, ya que de esta forma se le puede entregar una respuesta oportuna al usuario. Aquellas transacciones de lectura que requieren una gran cantidad de tiempo en ser resueltas degradan considerablemente la satisfacción del usuario, y es por esto que las máquinas de búsqueda están optimizadas para reducir el percentil más alto de los tiempos (también llamado \textit{tail latency}) \citep{Jeon:2014}. Paralelizar el procesamiento de cada consulta es una solución promitente para reducir el tiempo de ejecución de estas \citep{Jeon:2013, Tatikonda:2011}, lo cual es posible gracias a los modernos procesadores que existen hoy en día que poseen múltiples núcleos, en donde se puede resolver una consulta paralelizando múltiples hilos de ejecución.

Conocer de antemano la eficiencia de una transacción de lectura es una ventaja muy importante, puesto que aquellas consultas que toman una mayor cantidad de tiempo en ser resueltas se les asigna un mayor número de hilos de ejecución para resolverla, de esta manera se reduce el tiempo de procesamiento de las consultas y se cumple con la cota superior de tiempo establecida. Permite implementar técnicas efectivas de procesamiento y de planificación de transacciones de lectura, por ejemplo, en el contexto de procesamiento paralelo de consultas por lotes (\textit{batches}), se pueden crear grupos de consultas que posean similares tiempos de respuesta, así se tiende a disminuir tanto el desbalance de carga entre los procesadores como el tiempo en procesar el lote completo.

Con el objetivo de construir estrategias de procesamiento y planificación de consultas eficientes, en el presente trabajo se lleva a cabo la implementación de dos métodos de predicción de rendimiento para transacciones de lectura. La construcción de estos métodos de predicción se lleva a cabo con el objetivo de disminuir el tiempo en resolver conjuntos de consultas y asegurar una cota superior de tiempo para cada una de ellas. Adicionalmente, se busca estudiar cómo estos métodos afectan el rendimiento de un motor de búsqueda bajo el contexto de procesamiento de consultas por lotes utilizando el método Wand \citep{Broder:2003} y Block Max Wand \citep{Ding:2011}.

\section{Método de predicción multilineal}
\label{scheduling:glasgow}
Este método predice el tiempo de respuesta de una transacción de lectura y está basado en una regresión lineal múltiple con 42 variables independientes \citep{Macdonald:2012}. Como la respuesta a una consulta debe ser rápida, los estadísticos obtenidos desde las listas invertidas son previamente calculados en la fase de indexamiento, y en ningún caso es parte del proceso de resolución de la consulta. Los puntajes de los documentos son obtenidos mediante el método de \textit{ranking} BM25. 

Si bien es cierto que la regresión lineal posee 42 variables independientes, desde las listas invertidas se extraerán solo 14 estadísticos, ya que las 42 variables independientes se forman aplicando funciones de agregación sobre estos estadísticos. El estudio y el análisis estadístico de cada una de las variables involucradas en la regresión y su impacto en el tiempo está disponible en \citep{Macdonald:2012, Hauff:2010, He:2004}. A continuación se describe cada uno de los estadísticos $s(t)$ calculados en el proceso de indexamiento \citep{Croft:2009} de un sistema de recuperación de información.


\begin{list}{}{}
	\item \textbf{Media aritmética}.

	\item \textbf{Media geométrica}.

	\item \textbf{Media harmónica}.

	\item \textbf{Máximo puntaje}. Se obtiene el puntaje máximo perteneciente a algún documento dentro de la lista invertida. En otras palabras, se obtiene el \textit{upper bound} $UB_t$ de la lista. 

	\item \textbf{Varianza del puntaje}. Se extrae desde la lista invertida del término $t$, la varianza del puntaje de los documentos. 
	
	\item \textbf{Número de documentos}. Largo de la lista invertida. 

	\item \textbf{Número de máximos}. Número de veces en que aparece un nuevo puntaje máximo, es decir, el número de veces en que el \textit{upper bound} es actualizado. 

	\item \textbf{Número de documentos mayor a la media}. Número de documentos con puntaje superior al puntaje promedio. 
	
	\item \textbf{Número de documentos con puntaje máximo}. Número de documentos que poseen el puntaje máximo en la lista invertida del término $t$. 
	
	\item \textbf{Número de documentos dentro del 5\% más alto}. Número de documentos cuyos puntajes están dentro del 5\% superior. 
	
	\item \textbf{Número de documentos dentro del 5\% del umbral (\textit{threshold})}. Número de documentos cuyos puntaje están dentro del 5\% superior o 5\% inferior al \textit{threshold}. Recordar que el \textit{threshold} es el puntaje más bajo dentro del conjunto de \textit{top-K}.
	
	\item \textbf{Número de inserciones en el conjunto de los mejores $K$ documentos}. Para obtener este estadístico se asume que el término $t$ es una consulta con un solo término, se resuelve esta consulta con el método Wand y se calcula el número de inserciones de documentos que se hizo al \textit{heap}. Recordar que las inserciones al \textit{heap} ocurren cuando el puntaje completo del documento, supera al \textit{threshold}.
	
	\item \textbf{Frecuencia inversa de documento del término}. Se calcula el \textit{idf} del término $t$ \citep{Baeza-Yates:2011}.
	
	\item \textbf{Tiempo en ser procesado el término}. Tiempo que toma en ser procesado el término como si fuese una consulta de un solo término.

\end{list}

Los 14 estadísticos descritos anteriormente son la base para la implementación del predictor y estos son calculados por cada término del índice invertido. Adicionalmente se definen tres funciones de agregación que se usarán por cada consulta: máximo, varianza y suma. El proceso es el siguiente, para cada consulta que llega al sistema, se toman los 14 estadísticos de cada uno de los términos que la conforman, luego se aplican las funciones de agregación a los estadísticos de los términos. Por ejemplo, suponga que llegan dos consultas al sistema $q_1$ y $q_2$, ambas tendrán asociadas un vector de 14 estadísticos $E_{q_1}$ y $E_{q_2}$ respectivamente, las funciones de agregación para el estadístico de la media aritmética será calculado como sigue: $e_1 = max\{E_{q_1}(0), E_{q_2}(0)\}$, $e_2 = var\{E_{q_1}(0), E_{q_2}(0)\}$, $e_3 = sum\{E_{q_1}(0), E_{q_2}(0)\}$. De esta forma, con solo el primer estadístico (la media aritmética) se obtienen tres variables independientes ($e_1$, $e_2$, $e_3$). Si esto se extrapola a cada estadístico, se obtienen los 42 requeridos por el método. 
La Tabla \ref{tabla:estadisticosGlasgow} muestra un resumen de lo escrito anteriormente en donde se muestra cada uno de los estadísticos y los agregadores a utilizar. 

\begin{table}[tp]
\centering
\caption{Resumen de los estadísticos para la predicción multilineal}
\begin{tabular}{|l|}
\hline
\multicolumn{1}{|c|}{Estadísticos de términos $s(t)$} \\ \hline
1. Media aritmética \\ 
2. Media geométrica \\ 
3. Media harmónica \\ 
4. Puntaje máximo \\ 
5. Varianza del puntaje \\ 
6. Número de documentos \\ 
7. Número de máximos \\ 
8. Número docs $>$ media \\ 
9. Número docs = máximo puntaje \\ 
10. Número docs dentro del 5\% más alto \\
11. Número docs dentro del 5\% del \textit{threshold} \\ 
12. Número de inserciones al conjunto \textit{top-K} \\ 
13. IDF \\ 
14. Tiempo en resolver $t$ como consulta \\ \hline
\multicolumn{1}{|c|}{Agregadores A()} \\ \hline
a. Máximo \\ 
b. Varianza  \\ 
c. Suma \\ \hline
\end{tabular}
\label{tabla:estadisticosGlasgow}
\end{table}

\section{Método de predicción neuronal}
\label{scheduling:neuronal}
Se implementa un método de predicción basado en una red neuronal \textit{backpropagation} \citep{Rumelhart:1988}. La característica de este tipo de redes es que utilizando al menos una capa oculta, se puede aproximar cualquier tipo de función o relación continua entre un grupo de variables de entrada y salida. Este tipo de redes neuronales utilizan un método de entrenamiento en el cual se propaga el error hacia atrás para ajustar los pesos de las diferentes neuronas del modelo, de esta forma la red neuronal va generando una asociación entre la entrada y salida \citep{Fausett:1994}.

Se implementa el modelo neuronal usando las mismas 42 variables independientes del método anterior, debido a que ya se ha demostrado que existe una relación lineal entre estas variables y la variable tiempo \citep{Macdonald:2012, Hauff:2010, He:2004}. El modelo consiste de dos neuronas en una capa oculta, la idea es que el tiempo que toma la predicción no genere un impacto negativo en el tiempo de procesamiento de la consulta, es por esto que se decide utilizar solo dos neuronas, sin embargo, en el Capítulo \ref{cap:evaluacionexperimental} también se hace un análisis del modelo con 10 y 20 neuronas en la capa oculta. El objetivo es minimizar el error de la estimación de tiempo y que la predicción no genere un impacto negativo en términos de tiempo.